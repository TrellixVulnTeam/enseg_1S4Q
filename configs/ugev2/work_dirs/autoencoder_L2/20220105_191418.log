2022-01-05 19:14:18,655 - enseg - INFO - Distributed training: True
2022-01-05 19:14:19,012 - enseg - INFO - Config:
dataset_type = 'UnpairedDataset'
data_root = '/home/wzx/weizhixiang/ensegment/data/enseg/nightcity'
aux_type = 'CityscapesDataset'
aux_root = '/home/wzx/weizhixiang/ensegment/data/enseg/cityscape'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (256, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1024, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(256, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=4,
    train=dict(
        type='UnpairedDataset',
        data_root='/home/wzx/weizhixiang/ensegment/data/enseg/nightcity',
        img_dir='image/train',
        ann_dir='label/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(1024, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(256, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ],
        aux_dataset=dict(
            type='CityscapesDataset',
            data_root='/home/wzx/weizhixiang/ensegment/data/enseg/cityscape',
            img_dir='image/train',
            ann_dir='label/train',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(
                    type='Resize',
                    img_scale=(1024, 512),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(256, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(256, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ])),
    val=dict(
        type='UnpairedDataset',
        data_root='/home/wzx/weizhixiang/ensegment/data/enseg/nightcity',
        img_dir='image/val',
        ann_dir='label/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        aux_dataset=dict(
            type='CityscapesDataset',
            data_root='/home/wzx/weizhixiang/ensegment/data/enseg/cityscape',
            img_dir='image/val',
            ann_dir='label/val',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(
                    type='MultiScaleFlipAug',
                    img_scale=(1024, 512),
                    flip=False,
                    transforms=[
                        dict(type='Resize', keep_ratio=True),
                        dict(type='RandomFlip'),
                        dict(
                            type='Normalize',
                            mean=[123.675, 116.28, 103.53],
                            std=[58.395, 57.12, 57.375],
                            to_rgb=True),
                        dict(type='ImageToTensor', keys=['img']),
                        dict(type='Collect', keys=['img'])
                    ])
            ])),
    test=dict(
        type='UnpairedDataset',
        data_root='/home/wzx/weizhixiang/ensegment/data/enseg/nightcity',
        img_dir='image/test',
        ann_dir='label/test',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        aux_dataset=dict(
            type='CityscapesDataset',
            data_root='/home/wzx/weizhixiang/ensegment/data/enseg/cityscape',
            img_dir='image/test',
            ann_dir='label/test',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(
                    type='MultiScaleFlipAug',
                    img_scale=(1024, 512),
                    flip=False,
                    transforms=[
                        dict(type='Resize', keep_ratio=True),
                        dict(type='RandomFlip'),
                        dict(
                            type='Normalize',
                            mean=[123.675, 116.28, 103.53],
                            std=[58.395, 57.12, 57.375],
                            to_rgb=True),
                        dict(type='ImageToTensor', keys=['img']),
                        dict(type='Collect', keys=['img'])
                    ])
            ])))
log_config = dict(
    interval=5,
    hooks=[
        dict(type='TextLoggerHook', by_epoch=False, interval=5),
        dict(type='VisualizationHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')
runner = dict(
    type='DynamicIterBasedRunner',
    is_dynamic_ddp=True,
    pass_training_status=True)
find_unused_parameters = True
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
norm_cfg = dict(type='SyncBN', requires_grad=True)
network = dict(
    type='AutoEncoder',
    rec=dict(
        type='BaseTranslator',
        encode_decode=dict(
            type='ResnetGenerator',
            in_channels=3,
            out_channels=3,
            base_channels=64,
            num_down=5,
            norm_cfg=dict(type='IN'),
            use_dropout=False,
            num_blocks=3,
            padding_mode='reflect',
            init_cfg=dict(type='normal', gain=0.02)),
        losses_cfg=dict(type='PixelLoss', loss_weight=1.0, loss_type='L2'),
        accept_img=['low', 'light']),
    noise_std=dict(light=0.2, low=0.05))
optimizer = dict(rec=dict(type='Adam', lr=0.001, betas=(0.5, 0.999)))
lr_config = dict(policy='poly', power=0.9, min_lr=1e-06, by_epoch=False)
total_iters = 1000
checkpoint_config = dict(by_epoch=False, interval=8000)
evaluation = None
work_dir = './work_dirs/autoencoder_L2'
gpu_ids = range(0, 2)

2022-01-05 19:14:19,013 - enseg - INFO - Set random seed to 42, deterministic: False
Name of parameter - Initialization information

rec.model.model.0.conv.weight - torch.Size([64, 3, 7, 7]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.0.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.1.conv.weight - torch.Size([128, 64, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.1.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.2.conv.weight - torch.Size([256, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.3.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.3.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.4.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.4.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.5.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.5.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.6.block.0.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.6.block.0.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.6.block.1.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.6.block.1.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.7.block.0.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.7.block.0.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.7.block.1.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.7.block.1.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.8.block.0.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.8.block.0.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.8.block.1.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.8.block.1.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.9.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.9.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.10.conv.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.10.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.11.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.11.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.12.conv.weight - torch.Size([256, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.12.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.13.conv.weight - torch.Size([128, 64, 3, 3]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.13.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of AutoEncoder  

rec.model.model.14.conv.weight - torch.Size([3, 64, 7, 7]): 
Initialized by user-defined `init_weights` in ResnetGenerator  

rec.model.model.14.conv.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of AutoEncoder  
2022-01-05 19:14:22,820 - enseg - INFO - Loaded 2570 images
2022-01-05 19:14:22,854 - enseg - INFO - Loaded 2975 images
2022-01-05 19:14:23,341 - enseg - INFO - Loaded 428 images
2022-01-05 19:14:23,347 - enseg - INFO - Loaded 500 images
2022-01-05 19:14:23,347 - enseg - INFO - Start running, host: wzx@amax, work_dir: /home/wzx/weizhixiang/ensegment/configs/ugev2/work_dirs/autoencoder_L2
2022-01-05 19:14:23,347 - enseg - INFO - workflow: [('train', 1)], max: 1000 iters
2022-01-05 19:14:23,347 - enseg - INFO - Checkpoints will be saved to /home/wzx/weizhixiang/ensegment/configs/ugev2/work_dirs/autoencoder_L2 by HardDiskBackend.
